{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "\n",
    "A1-Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model. The overfitted model has low bias and high variance.\n",
    "To mitigate it -Cross-Validation,Training with more data,Removing features,Early stopping the training etc.\n",
    "\n",
    "\n",
    "In the case of underfitting, the model is not able to learn enough from the training data, and hence it reduces the accuracy and produces unreliable predictions.\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "A2-Some ways to reduce the occurrence of overfitting in our model-:\n",
    "Cross-Validation\n",
    "Training with more data\n",
    "Removing features\n",
    "Early stopping the training\n",
    "Regularization\n",
    "Ensembling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "A3-In the case of underfitting, the model is not able to learn enough from the training data, and hence it reduces the accuracy and produces unreliable predictions.An underfitted model has high bias and low variance.\n",
    "scenario of underfitting in ml model-:\n",
    "1.Data used for training is not cleaned and contains noise (garbage values) in it.\n",
    "2.The model has a high bias.\n",
    "3.The size of the training dataset used is not enough.\n",
    "4.The model is too simple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "\n",
    "A4-In machine learning, as you try to minimize one component of the error (bias), the other component (variance) tends to increase, and vice versa. Finding the right balance of bias and variance is key to creating an effective and accurate model. This is called the bias-variance tradeoff.\n",
    "Bias and variance are inversely proportional to each other.A model that exhibits small variance and high bias will underfit the target, while a model with high variance and little bias will overfit the target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "A5-The methods for detecting overfitting and underfitting are-:\n",
    "1.Cross-Validation\n",
    "2.Learning Curves\n",
    "3.Validation Curves\n",
    "4.Evaluation Metrics\n",
    "5.Model Complexity Analysis\n",
    "6.Residual Analysi\n",
    "\n",
    "Overfitting models produce good predictions for data points in the training set but perform poorly on new samples. Underfitting occurs when the machine learning model is not well-tuned to the training set. The resulting model is not capturing the relationship between input and output well enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "A6-Bias and variance are negatively related to one another and it is extremely unlikely that a machine learning model could have both a low bias and a low variance at the same time.In contrast to bias, variance describes the situation in which the model accounts for the variations in the data as well as the noise. If you try to change the algorithm so that it is more suitable for a certain dataset, it may end up having a low bias, but the variance will increase.\n",
    "\n",
    "\n",
    "High bias models typically exhibit underfitting, meaning they oversimplify the underlying patterns in the data. Examples include linear regression with few features for a complex dataset or a shallow decision tree for nonlinear data. These models have limited capacity to capture the true relationship between features and target, resulting in systematic errors.\n",
    "High variance models, on the other hand, often lead to overfitting, capturing noise in the training data as if it were true patterns. Examples include deep neural networks with many layers for a small dataset or decision trees with high depth for noisy data. These models perform well on training data but generalize poorly to unseen data, indicating high sensitivity to small fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "\n",
    "A7-Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it. \n",
    "\n",
    "There are two main types of regularization techniques: \n",
    "1.Ridge Regularization- Also known as Ridge Regression, it modifies the over-fitted or under fitted models by adding the penalty equivalent to the sum of the squares of the magnitude of coefficients.\n",
    "\n",
    "Lasso Regularization-It modifies the over-fitted or under-fitted models by adding the penalty equivalent to the sum of the absolute values of coefficients. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
